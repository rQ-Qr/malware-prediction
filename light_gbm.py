import pandas as pd
import numpy as np
import lightgbm as lgb
from scipy.sparse import vstack, csr_matrix, save_npz, load_npz
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
import gc  # garbage collector

gc.enable()

dtypes = {
    'MachineIdentifier': 'category',
    'ProductName': 'category',
    'EngineVersion': 'category',
    'AppVersion': 'category',
    'AvSigVersion': 'category',
    'IsBeta': 'int8',
    'RtpStateBitfield': 'float32',
    'IsSxsPassiveMode': 'int8',
    'DefaultBrowsersIdentifier': 'float32',
    'AVProductStatesIdentifier': 'float32',
    'AVProductsInstalled': 'float32',
    'AVProductsEnabled': 'float32',
    'HasTpm': 'int8',
    'CountryIdentifier': 'int16',
    'CityIdentifier': 'float32',
    'OrganizationIdentifier': 'float32',
    'GeoNameIdentifier': 'float32',
    'LocaleEnglishNameIdentifier': 'int8',
    'Platform': 'category',
    'Processor': 'category',
    'OsVer': 'category',
    'OsBuild': 'int16',
    'OsSuite': 'int16',
    'OsPlatformSubRelease': 'category',
    'OsBuildLab': 'category',
    'SkuEdition': 'category',
    'IsProtected': 'float32',
    'AutoSampleOptIn': 'int8',
    'PuaMode': 'category',
    'SMode': 'float32',
    'IeVerIdentifier': 'float32',
    'SmartScreen': 'category',
    'Firewall': 'float32',
    'UacLuaenable': 'float32',
    'Census_MDC2FormFactor': 'category',
    'Census_DeviceFamily': 'category',
    'Census_OEMNameIdentifier': 'float32',
    'Census_OEMModelIdentifier': 'float32',
    'Census_ProcessorCoreCount': 'float32',
    'Census_ProcessorManufacturerIdentifier': 'float32',
    'Census_ProcessorModelIdentifier': 'float32',
    'Census_ProcessorClass': 'category',
    'Census_PrimaryDiskTotalCapacity': 'float32',
    'Census_PrimaryDiskTypeName': 'category',
    'Census_SystemVolumeTotalCapacity': 'float32',
    'Census_HasOpticalDiskDrive': 'int8',
    'Census_TotalPhysicalRAM': 'float32',
    'Census_ChassisTypeName': 'category',
    'Census_InternalPrimaryDiagonalDisplaySizeInInches': 'float32',
    'Census_InternalPrimaryDisplayResolutionHorizontal': 'float32',
    'Census_InternalPrimaryDisplayResolutionVertical': 'float32',
    'Census_PowerPlatformRoleName': 'category',
    'Census_InternalBatteryType': 'category',
    'Census_InternalBatteryNumberOfCharges': 'float32',
    'Census_OSVersion': 'category',
    'Census_OSArchitecture': 'category',
    'Census_OSBranch': 'category',
    'Census_OSBuildNumber': 'int16',
    'Census_OSBuildRevision': 'int32',
    'Census_OSEdition': 'category',
    'Census_OSSkuName': 'category',
    'Census_OSInstallTypeName': 'category',
    'Census_OSInstallLanguageIdentifier': 'float32',
    'Census_OSUILocaleIdentifier': 'int16',
    'Census_OSWUAutoUpdateOptionsName': 'category',
    'Census_IsPortableOperatingSystem': 'int8',
    'Census_GenuineStateName': 'category',
    'Census_ActivationChannel': 'category',
    'Census_IsFlightingInternal': 'float32',
    'Census_IsFlightsDisabled': 'float32',
    'Census_FlightRing': 'category',
    'Census_ThresholdOptIn': 'float32',
    'Census_FirmwareManufacturerIdentifier': 'float32',
    'Census_FirmwareVersionIdentifier': 'float32',
    'Census_IsSecureBootEnabled': 'int8',
    'Census_IsWIMBootEnabled': 'float32',
    'Census_IsVirtualDevice': 'float32',
    'Census_IsTouchEnabled': 'int8',
    'Census_IsPenCapable': 'int8',
    'Census_IsAlwaysOnAlwaysConnectedCapable': 'float32',
    'Wdft_IsGamer': 'float32',
    'Wdft_RegionIdentifier': 'float32',
    'HasDetections': 'int8'
}

remove_cols = ['PuaMode', 'Census_ProcessorClass', 'Census_IsWIMBootEnabled', 'IsBeta', 'Census_IsFlightsDisabled',
               'Census_IsFlightingInternal', 'AutoSampleOptIn', 'Census_ThresholdOptIn', 'SMode',
               'Census_IsPortableOperatingSystem', 'Census_DeviceFamily', 'UacLuaenable', 'Census_IsVirtualDevice',
               'Platform', 'Census_OSSkuName', 'Census_OSInstallLanguageIdentifier', 'Processor']


def preprocess(sample=True):
    train_file = './train.csv'
    test_file = './test.csv'
    column_lower_limit = 1000

    if sample:
        train_file = './train_sample.csv'
        test_file = './test_sample.csv'
        column_lower_limit = 10

    print('Read Train and Test Data.\n')
    train = pd.read_csv(train_file, dtype=dtypes, low_memory=True)
    test = pd.read_csv(test_file, dtype=dtypes, low_memory=True)

    # remove unnecessary lines
    # 1.Mostly-missing features
    # 2.Too-skewed features
    # 3.Highly-correlated features
    train.drop(remove_cols, axis=1, inplace=True)
    test.drop(remove_cols, axis=1, inplace=True)

    # Reset the MachineIdentifier as index
    train['MachineIdentifier'] = train.index.astype('uint32')
    test['MachineIdentifier'] = test.index.astype('uint32')

    gc.collect()

    print('Transform all features to values.\n')
    for column in train.columns.tolist()[1:-1]:
        # First set the type as string
        train[column] = train[column].astype('str')
        test[column] = test[column].astype('str')

        # Fit LabelEncoder
        label_encoder = LabelEncoder().fit(
            np.unique(train[column].unique().tolist() +
                      test[column].unique().tolist())
        )

        # The start value is 1, 0 will be used for dropped values
        train[column] = label_encoder.transform(train[column]) + 1
        test[column] = label_encoder.transform(test[column]) + 1

        # Group the data by the curren column to
        # 1. remove observations less than the lower limit
        # 2. remove unbalanced values between training set and test set
        aggregate_train = (train
                           .groupby([column])
                           .aggregate({'MachineIdentifier': 'count'})
                           .reset_index()
                           .rename({'MachineIdentifier': 'Train'}, axis=1))
        aggregate_test = (test
                          .groupby([column])
                          .aggregate({'MachineIdentifier': 'count'})
                          .reset_index()
                          .rename({'MachineIdentifier': 'Test'}, axis=1))

        aggregate = pd.merge(aggregate_train, aggregate_test, on=column, how='outer').replace(np.nan, 0)

        # Select values the number of which in training set is higher than the lower limit
        aggregate = aggregate[(aggregate['Train'] > column_lower_limit)].reset_index(drop=True)
        # Get the total number of a specific value
        aggregate['Total'] = aggregate['Train'] + aggregate['Test']

        # Drop unbalanced values
        # The ratio of the number in training set and test set is between 0.2 and 0.8
        aggregate = aggregate[
            (aggregate['Train'] / aggregate['Total'] > 0.2) & (aggregate['Train'] / aggregate['Total'] < 0.8)]
        aggregate[column + '_copy'] = aggregate[column]

        # Only keep balanced values with number more than lower limit
        # For other values, replace them to 0
        train[column] = (pd.merge(train[[column]],
                                  aggregate[[column, column + '_copy']],
                                  on=column, how='left')[column + '_copy']
                         .replace(np.nan, 0).astype('int').astype('category'))

        test[column] = (pd.merge(test[[column]],
                                 aggregate[[column, column + '_copy']],
                                 on=column, how='left')[column + '_copy']
                        .replace(np.nan, 0).astype('int').astype('category'))

        del label_encoder, aggregate_train, aggregate_test, aggregate, column
        gc.collect()

    y_train = np.array(train['HasDetections'])
    train_ids = train.index
    test_ids = test.index

    del train['HasDetections'], train['MachineIdentifier'], test['MachineIdentifier']
    gc.collect()

    # Fit OneHotEncoder
    ohe = OneHotEncoder(categories='auto', sparse_output=True, dtype='uint8').fit(train)

    # Transform data using small groups to reduce memory usage
    cnt = 100000
    train = vstack([ohe.transform(train[i * cnt:(i + 1) * cnt]) for i in range(train.shape[0] // cnt + 1)])
    test = vstack([ohe.transform(test[i * cnt:(i + 1) * cnt]) for i in range(test.shape[0] // cnt + 1)])
    save_npz('train.npz', train, compressed=True)
    save_npz('test.npz', test, compressed=True)

    del ohe
    gc.collect()

    return train_ids, test_ids, y_train


def light_gbm():

    train_ids, test_ids, y_train = preprocess()

    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    skf.get_n_splits(train_ids, y_train)

    lgb_test_result = np.zeros(test_ids.shape[0])
    counter = 0

    print('\nLightGBM\n')
    cnt = 100000
    for train_index, test_index in skf.split(train_ids, y_train):
        print('Fold {}\n'.format(counter + 1))

        train = load_npz('train.npz')
        x_fit = vstack([train[train_index[i * cnt:(i + 1) * cnt]] for i in range(train_index.shape[0] // cnt + 1)])
        x_val = vstack([train[test_index[i * cnt:(i + 1) * cnt]] for i in range(test_index.shape[0] // cnt + 1)])
        x_fit, x_val = csr_matrix(x_fit, dtype='float32'), csr_matrix(x_val, dtype='float32')
        y_fit, y_val = y_train[train_index], y_train[test_index]

        del train
        gc.collect()

        lgb_model = lgb.LGBMClassifier(max_depth=-1,
                                       n_estimators=30000,
                                       learning_rate=0.05,
                                       num_leaves=2 ** 6 - 1,
                                       colsample_bytree=0.28,
                                       objective='binary',
                                       n_jobs=-1)

        lgb_model.fit(x_fit, y_fit, eval_metric='auc', eval_set=[(x_val, y_val)])

        pred = lgb_model.predict(x_val)
        num = accuracy_score(y_val, pred)
        print("Testing accuracy {:.4f}".format(num))

        del x_fit, x_val, y_fit, y_val, train_index, test_index
        gc.collect()

        test = load_npz('test.npz')
        test = csr_matrix(test, dtype='float32')
        lgb_test_result += lgb_model.predict_proba(test)[:, 1]
        counter += 1

        del test
        gc.collect()

    result = pd.read_csv('test_sample_lgbm.csv')
    result['HasDetections'] = lgb_test_result / counter
    result.to_csv('test_sample_lgbm.csv', index=False)


if __name__ == '__main__':
    light_gbm()
